# The Power of Context: An In-depth Analysis of Large Language Models and Their Evaluation Using Custom-Tailored Benchmark Sets

This work examines the impact of varying context lengths on the output of large language models(LLMs) and explores the performance of these models after training with additional information.

## Code Introduction

+ **Benchmark**

  This folder contains the four evaluation metrics for language models: BLEU, ROUGE, Perplexity, and WMD, along with their summaries.

  BLEU:

  ROUGE:

  Perplexity:

  WMD:

+ **Datenbank**

mysql

+ **Datenset**

da

+ **Diagramm**

da

+ **Kontexterstellung**

da

+ **Eingabe**



+ **Training**
